<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>concurrency on PMem.io</title><link>https://pmem.io/tags/concurrency/</link><description>Recent content in concurrency on PMem.io</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 30 Mar 2022 15:11:18 +0200</lastBuildDate><atom:link href="https://pmem.io/tags/concurrency/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic asynchronous hashmap with Miniasync library</title><link>https://pmem.io/blog/2022/03/basic-asynchronous-hashmap-with-miniasync-library/</link><pubDate>Wed, 30 Mar 2022 15:11:18 +0200</pubDate><guid>https://pmem.io/blog/2022/03/basic-asynchronous-hashmap-with-miniasync-library/</guid><description>Miniasync library provides a framework for the composition and execution of asynchronous tasks in C. In order to accomodate different user-defined tasks and various types of data that they take in, libminiasync makes use of macros.
Using libminiasync for the first time can be challenging. There are multiple examples on the miniasync repo to make it easier. One of them is hashmap example.
Creating a future Future is an abstraction of asynchronous task.</description></item><item><title>Leveraging asynchronous hardware accelerators for fun and profit</title><link>https://pmem.io/blog/2022/02/leveraging-asynchronous-hardware-accelerators-for-fun-and-profit/</link><pubDate>Mon, 28 Feb 2022 10:00:00 +0000</pubDate><guid>https://pmem.io/blog/2022/02/leveraging-asynchronous-hardware-accelerators-for-fun-and-profit/</guid><description>One of the greatest benefits of Persistent Memory is that it&amp;rsquo;s directly accessible by the CPU. But that can also be one of its downsides for specific use cases. For example, if you want to use PMem as an ultra-fast storage device with low access latency.
PMem as storage impedance mismatch The reason for that is simple - block storage I/O is typically asynchronous due to its relatively high latency and high queue depths required to reach optimal throughputs.</description></item></channel></rss>